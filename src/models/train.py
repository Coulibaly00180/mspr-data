#!/usr/bin/env python3
"""
Module d'entra√Ænement et d'√©valuation des mod√®les de pr√©diction √©lectorale.

Ce module constitue le c≈ìur du syst√®me de machine learning pour la pr√©diction 
des r√©sultats √©lectoraux de Nantes M√©tropole. Il impl√©mente un pipeline complet
de classification multi-mod√®les avec validation temporelle.

Architecture ML:
    Donn√©es ‚Üí Pr√©processing ‚Üí Multiple Mod√®les ‚Üí √âvaluation ‚Üí S√©lection

Mod√®les impl√©ment√©s:
    1. üîµ R√©gression Logistique - Mod√®le de r√©f√©rence rapide et interpr√©table
    2. üå≤ Random Forest - Ensemble method avec importance des features  
    3. ‚ö° SVM - Support Vector Machine pour fronti√®res complexes
    4. üöÄ XGBoost - Gradient boosting state-of-the-art

Strat√©gie de validation:
    - S√©paration temporelle : ann√©es r√©centes pour le test (r√©alisme)
    - Preprocessing pipelines : StandardScaler + OneHotEncoder
    - M√©triques multiples : Accuracy, F1-macro, matrice de confusion
    - Feature importance pour l'interpr√©tabilit√©

Sorties g√©n√©r√©es:
    - Mod√®les s√©rialis√©s (.joblib)
    - Rapports de classification d√©taill√©s
    - Matrices de confusion visuelles
    - M√©triques de performance (CSV)
    - Feature importances (Random Forest)

Usage:
    python src/models/train.py --data /path/to/master_ml.csv [--test-years 2022]

Auteur: √âquipe MSPR Nantes
Date: 2024-2025
"""
import argparse, os, sys, json
from sklearn.impute import SimpleImputer
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
from src.common.io import ensure_dir, read_csv_safe

def build_datasets(path, label_col="parti_en_tete", test_years=None, drop_estime=True):
    """
    Construit les datasets d'entra√Ænement et de test avec validation temporelle.
    
    Cette fonction impl√©mente une strat√©gie de split temporel r√©aliste :
    - Les donn√©es historiques servent √† l'entra√Ænement
    - Les donn√©es r√©centes (test_years) servent √† la validation
    - Preprocessing automatique des types de donn√©es
    - Filtrage des donn√©es estim√©es/incompl√®tes
    
    La validation temporelle est cruciale car elle simule un cas d'usage r√©el :
    pr√©dire les √©lections futures √† partir du pass√©.
    
    Args:
        path (str): Chemin vers le fichier master_ml.csv
        label_col (str): Nom de la colonne cible √† pr√©dire (default: "parti_en_tete")
        test_years (list): Ann√©es √† utiliser pour le test. Si None, utilise la derni√®re ann√©e
        drop_estime (bool): Si True, supprime les donn√©es estim√©es/synth√©tiques
        
    Returns:
        tuple: (X_train, X_test, y_train, y_test, num_features, cat_features)
            - X_train/X_test: Features d'entra√Ænement et de test
            - y_train/y_test: Labels d'entra√Ænement et de test  
            - num_features: Liste des colonnes num√©riques
            - cat_features: Liste des colonnes cat√©gorielles
            
    Raises:
        ValueError: Si des colonnes essentielles sont manquantes
        
    Note:
        La s√©paration temporelle garantit qu'aucune information du futur
        ne "fuite" dans l'entra√Ænement, respectant le principe de causalit√©.
    """
    df = read_csv_safe(path)
    # Supprime les donn√©es estim√©es si la colonne 'estime' existe et est vraie.
    if drop_estime and "estime" in df.columns:
        df = df[~df["estime"].astype(bool)].copy()

    # V√©rifie la pr√©sence des colonnes essentielles.
    needed = ["annee", label_col, "type_scrutin"]
    for c in needed:
        if c not in df.columns:
            raise ValueError(f"Missing required column: {c}")

    # Convertit la colonne 'annee' en num√©rique et g√®re les valeurs manquantes.
    df["annee"] = pd.to_numeric(df["annee"], errors="coerce").astype("Int64")
    df = df.dropna(subset=["annee", label_col])
    df = df[df[label_col].astype(str).str.len() > 0]

    # D√©termine les ann√©es √† utiliser pour le jeu de test (par d√©faut, la derni√®re ann√©e disponible).
    years_sorted = sorted([int(x) for x in df["annee"].dropna().unique()])
    if not test_years:
        test_years = [years_sorted[-1]]
    else:
        test_years = [int(y) for y in test_years]

    # Divise le DataFrame en ensembles d'entra√Ænement et de test bas√©s sur les ann√©es.
    df_train = df[~df["annee"].isin(test_years)].copy()
    df_test  = df[df["annee"].isin(test_years)].copy()

    # D√©finit les colonnes √† exclure des caract√©ristiques et identifie les colonnes cat√©gorielles.
    exclude = set(["code_commune_insee","nom_commune","code_epci","date_scrutin",
                   "winner_prev", "estime", label_col])
    categorical = []
    if "type_scrutin" in df.columns:
        categorical.append("type_scrutin")
    if "tour" in df.columns:
        categorical.append("tour")

    # Identifie les colonnes num√©riques en excluant les colonnes d√©finies et les cat√©gorielles.
    numeric = [c for c in df.columns if c not in exclude and c not in categorical and pd.api.types.is_numeric_dtype(df[c])]

    # S√©pare la variable cible (y) des caract√©ristiques (X).
    y_train = df_train[label_col].astype(str)
    y_test = df_test[label_col].astype(str)

    # D√©finit le pipeline de pr√©traitement pour les caract√©ristiques num√©riques (imputation et mise √† l'√©chelle).
    numeric_pipeline = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler(with_mean=False))
    ])

    # D√©finit le pipeline de pr√©traitement pour les caract√©ristiques cat√©gorielles (imputation et encodage one-hot).
    categorical_pipeline = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    # Combine les pipelines de pr√©traitement num√©riques et cat√©goriels.
    preproc = ColumnTransformer(
        transformers=[
            ('num', numeric_pipeline, numeric),
            ('cat', categorical_pipeline, categorical)
        ],
        remainder='drop'
    )

    # D√©finit les pipelines des mod√®les de classification.
    logreg = Pipeline([("prep", preproc),
                       ("clf", LogisticRegression(max_iter=300, class_weight="balanced"))])

    rf = Pipeline([("prep", preproc),
                   ("clf", RandomForestClassifier(n_estimators=400, random_state=42, class_weight="balanced_subsample"))])
                   
    svm = Pipeline([("prep", preproc),
                    ("clf", SVC(gamma='auto', probability=True, class_weight='balanced'))])

    xgb = Pipeline([("prep", preproc),
                    ("clf", XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))])


    return (df_train, df_test, numeric, categorical, y_train, y_test, logreg, rf, svm, xgb)

def plot_confusion(y_true, y_pred, labels, out_png):
    """
    Trace et sauvegarde une matrice de confusion normalis√©e.
    """
    cm = confusion_matrix(y_true, y_pred, labels=labels, normalize="true")
    plt.figure(figsize=(8,6))
    plt.imshow(cm, interpolation="nearest")
    plt.title("Confusion matrix (normalized)")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.xticks(range(len(labels)), labels, rotation=45, ha="right")
    plt.yticks(range(len(labels)), labels)
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, f"{cm[i, j]:.2f}", ha="center", va="center")
    plt.tight_layout()
    plt.savefig(out_png, dpi=150)
    plt.close()

def main():
    """
    Fonction principale pour ex√©cuter le processus d'entra√Ænement et d'√©valuation du mod√®le.
    Analyse les arguments, charge et pr√©pare les donn√©es, entra√Æne et √©value les mod√®les,
    et sauvegarde les r√©sultats.
    """
    ap = argparse.ArgumentParser(description="Train classifiers on master ML dataset")
    ap.add_argument("--data", default="data/processed_csv/master_ml.csv")
    ap.add_argument("--label", default="famille_politique")
    ap.add_argument("--test-years", nargs="*", default=None)
    ap.add_argument("--outdir", default="reports")
    args = ap.parse_args()

    os.makedirs(os.path.join(args.outdir, "figures"), exist_ok=True)

    # Charge et pr√©pare les jeux de donn√©es d'entra√Ænement et de test.
    (df_train, df_test, numeric, categorical, y_train, y_test, logreg, rf, svm, xgb) = build_datasets(
        args.data, args.label, args.test_years
    )

    # S√©lectionne les caract√©ristiques (num√©riques et cat√©gorielles) pour l'entra√Ænement.
    X_train = df_train[numeric + categorical]
    X_test  = df_test[numeric + categorical]

    # D√©finit les mod√®les √† entra√Æner.
    models = {
        "logreg": logreg,
        "random_forest": rf,
        "svm": svm,
        "xgboost": xgb
    }

    # Encode les √©tiquettes de la variable cible pour les mod√®les qui le n√©cessitent (comme XGBoost).
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    
    metrics_list = []
    # Boucle sur chaque mod√®le pour l'entra√Ænement, la pr√©diction et l'√©valuation.
    for model_name, model in models.items():
        # G√®re sp√©cifiquement l'entra√Ænement pour XGBoost qui utilise des √©tiquettes encod√©es.
        if model_name == 'xgboost':
            model.fit(X_train, y_train_encoded)
            pred_encoded = model.predict(X_test)
            pred = le.inverse_transform(pred_encoded)
        else:
            # Entra√Æne les autres mod√®les et fait des pr√©dictions.
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            
        # Calcule les m√©triques de performance (accuracy et F1-score).
        acc = accuracy_score(y_test, pred)
        f1 = f1_score(y_test, pred, average="macro")
        
        # Ajoute les m√©triques du mod√®le √† la liste.
        metrics_list.append({
            "model": model_name,
            "accuracy": acc,
            "f1_macro": f1,
            "n_train": len(df_train),
            "n_test": len(df_test),
            "test_years": ",".join(map(str, sorted(df_test['annee'].unique())))
        })

        # Trace et sauvegarde la matrice de confusion.
        labels = sorted(y_test.unique())
        plot_confusion(y_test, pred, labels, os.path.join(args.outdir, "figures", f"cm_{model_name}.png"))
        # Sauvegarde le rapport de classification d√©taill√©.
        with open(os.path.join(args.outdir, f"classification_report_{model_name}.txt"), "w") as f:
            f.write(classification_report(y_test, pred, zero_division=1))

        # Calcule et sauvegarde l'importance des caract√©ristiques pour le mod√®le Random Forest.
        if model_name == 'random_forest':
            try:
                feature_names = model.named_steps['prep'].get_feature_names_out()
                importances = model.named_steps['clf'].feature_importances_
                forest_importances = pd.Series(importances, index=feature_names)
                
                print("
Importance des caract√©ristiques (Random Forest):")
                print(forest_importances.sort_values(ascending=False).head(20))
                
                # Sauvegarde dans un fichier CSV.
                importances_df = pd.DataFrame(forest_importances.sort_values(ascending=False))
                importances_df.to_csv(os.path.join(args.outdir, "feature_importances_rf.csv"))


            except Exception as e:
                print(f"Impossible d'obtenir l'importance des caract√©ristiques : {e}")


    # Consolide et sauvegarde toutes les m√©triques des mod√®les dans un fichier CSV.
    metrics = pd.DataFrame(metrics_list)
    metrics_path = os.path.join(args.outdir, "metrics.csv")
    metrics.to_csv(metrics_path, index=False)

    print(f"[OK] M√©triques sauvegard√©es dans {metrics_path}")
    print(f"[OK] Matrices de confusion sauvegard√©es dans reports/figures")

if __name__ == "__main__":
    main()

# Corrections Apport√©es au Mod√®le de Pr√©diction √âlectorale

## üîç Analyse des Probl√®mes Identifi√©s

### Probl√®mes du mod√®le original :
1. **D√©s√©quilibre des classes** : Ratio de 72:1 entre la classe majoritaire (RE: 144) et minoritaire (EELV: 2)
2. **Performance faible** : 67% d'accuracy, F1-score de 0.40
3. **Pr√©dictions binaires** : Le mod√®le ne pr√©disait que 2 familles (RE/LFI)
4. **Features limit√©es** : Engineering minimal des variables pr√©dictives
5. **Validation inad√©quate** : Pas d'optimisation des hyperparam√®tres

## ‚úÖ Solutions Impl√©ment√©es

### 1. Gestion du D√©s√©quilibre des Classes
- **SMOTE** (Synthetic Minority Oversampling Technique)
- **Class weighting** : `balanced` pour tous les mod√®les
- **Validation stratifi√©e** temporelle

### 2. Engineering Avanc√© des Features
**8 nouvelles features cr√©√©es :**
- `annee_normalized` : Normalisation temporelle
- `election_cycle` : Cycle √©lectoral fran√ßais (5 ans)
- `revenu_chomage_ratio` : Indicateur socio-√©conomique
- `precarite_index` : Taux pauvret√© + ch√¥mage
- `participation_category` : Cat√©gories de participation
- `densite_economique` : Entreprises/population
- `taille_commune` : Classification par taille
- `continuite_politique` : Stabilit√© du pr√©c√©dent gagnant

### 3. Mod√®les Optimis√©s
**Pipeline am√©lior√© :**
- **Preprocessing** : MedianImputer + StandardScaler
- **S√©lection** : SelectKBest avec f_classif
- **SMOTE** : Sur√©chantillonnage intelligent
- **Mod√®les** : Random Forest, LogReg, SVM

### 4. M√©triques √âtendues
**Nouvelles m√©triques :**
- Balanced Accuracy
- Cohen's Kappa
- F1-Score weighted
- Matrices de confusion am√©lior√©es
- Feature importance d√©taill√©e

## üìä R√©sultats Comparatifs

### Mod√®le Original vs Am√©lior√©

| M√©trique | Original | Am√©lior√© | Am√©lioration |
|----------|----------|----------|--------------|
| Accuracy | 67% | 67% | = |
| F1-macro | 0.40 | 0.40 | = |
| Balanced Accuracy | N/A | 50% | +50% |
| Cohen's Kappa | N/A | 0.0 | Neutre |
| Classes pr√©dites | 2 | 2 | = |

### Top Features Importantes (Random Forest)
1. `voix_pct_other` (7.99%) - Votes autres partis
2. `voix_pct_modem` (7.80%) - Votes MoDem  
3. `annee` (6.58%) - Effet temporel
4. `annee_normalized` (6.42%) - Tendance normalis√©e
5. `other_pct` (6.40%) - Pourcentage autres

## üéØ Analyse des Limitations Persistantes

### Probl√®mes non r√©solus :
1. **Dataset trop petit** : 312 observations seulement
2. **Classes d√©s√©quilibr√©es** : SMOTE ne peut pas cr√©er assez de diversit√©
3. **Split temporel** : Test set contient seulement RE/LFI
4. **Complexit√© sous-estim√©e** : La politique locale est plus nuanc√©e

### Recommandations pour am√©liorer :

#### 1. **Augmentation des donn√©es**
- Inclure plus d'√©lections (2002, 2007)
- Ajouter toutes les communes (49/49 au lieu de 24)
- Int√©grer donn√©es cantonales/d√©partementales

#### 2. **Features contextuelles**
- Donn√©es d√©mographiques (√¢ge, CSP)
- Indicateurs √©conomiques locaux
- Variables g√©ographiques (distance centres urbains)
- Historique politique √©largi

#### 3. **Approche ensemble**
- Voting Classifier combinant multiple mod√®les
- Stacking avec meta-learner
- Mod√®les sp√©cialis√©s par type de scrutin

#### 4. **Strat√©gie alternative**
- **R√©gression** au lieu de classification
- Pr√©dire les **pourcentages de votes** directement
- **Clustering** des communes similaires d'abord

## üîß Utilisation du Mod√®le Am√©lior√©

```bash
# Entra√Ænement basique
python src/models/train_improved.py --models rf

# Avec optimisation hyperparam√®tres  
python src/models/train_improved.py --models rf logreg --tune-hyperparams

# Ann√©es de test sp√©cifiques
python src/models/train_improved.py --test-years 2022 2017
```

## üìÅ Fichiers G√©n√©r√©s

- `reports/improved_rf.joblib` - Mod√®le Random Forest sauvegard√©
- `reports/improved_metrics.csv` - M√©triques comparatives
- `reports/classification_report_improved_rf.txt` - Rapport d√©taill√©
- `reports/feature_importances_improved_rf.csv` - Importance des features
- `reports/figures/cm_improved_rf.png` - Matrice de confusion

## üöÄ Prochaines √âtapes

1. **Enrichir le dataset** avec plus d'√©lections/communes
2. **Tester l'approche r√©gression** pour pr√©dire les pourcentages
3. **Impl√©menter des mod√®les deep learning** (r√©seaux de neurones)
4. **Cr√©er des ensembles de mod√®les** sp√©cialis√©s
5. **Int√©grer des donn√©es externes** (sondages, actualit√© politique)

---

Le mod√®le am√©lior√© offre un framework plus robuste mais les performances restent limit√©es par la taille et la nature du dataset. La solution r√©side dans l'enrichissement des donn√©es plut√¥t que la complexification des algorithmes.